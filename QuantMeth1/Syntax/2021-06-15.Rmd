---
title: "Kapitel 4, ARM"
author: "ses"
date: "6/15/2021"
output: 
  html_document:
    toc: TRUE
    number_sections: TRUE
editor_options: 
  chunk_output_type: console
---

# Quelle

<https://sebastiansauer.github.io/2021-sose/QuantMeth1/Syntax/2021-06-15.html>



# Pakete laden

```{r message = FALSE}
library(tidyverse)
library(arm)  # nicht wirklich wichtig, nur für Funktion "display"
```


# Lineare Transformationen 1: Linearen Einfluss auf Regressionsgewichte, kein Einfluss auf $R^2$



## Daten laden: `earn`

Vgl. S. 53 in ARM, Kap. 4:

```{r}
earn <- read_csv("https://raw.githubusercontent.com/sebastiansauer/2021-sose/master/data/ARM/heights.csv")
```


```{r}
glimpse(earn)
```

Wir ändern die Skalierung des Prädiktors (Varianz, sd). Was hat das für die Regr.gewichte und für $R^2$?

## lm0

```{r}
lm0 <- lm(earn ~ height, 
          data = earn)
display(lm0)
```


```{r}
earn <-
  earn %>% 
  mutate(height_cm = height / 2.54,
         height_mm = height_cm / 10,
         height_m = height_cm * 100)
```

```{r}
lm0a <- lm(earn ~ height_cm, 
          data = earn)
display(lm0a)
```


```{r}
lm0b <- lm(earn ~ height_mm, 
          data = earn)
display(lm0b)
```


```{r}
lm0c <- lm(earn ~ height_m, 
          data = earn)
display(lm0c)
```


# Lineare Transformationen 2: Zentrieren und z-Transformationen


## Daten laden: `kidsiq`

S. 55., 4.2 ARM:

```{r}
kidsiq <- read_csv("https://raw.githubusercontent.com/sebastiansauer/2021-sose/master/data/ARM/kidsiq.csv")
```

## lm1: Interaktionseffekt

```{r}
lm1 <- lm(kid_score ~ mom_hs + mom_iq + mom_hs:mom_iq,
          data = kidsiq)
display(lm1)
```

Interpretation!



## lm2: Zentrieren 

```{r}
kidsiq <-
  kidsiq %>% 
  mutate(mom_hs_c = mom_hs - mean(mom_hs),
         mom_iq_c = mom_iq - mean(mom_iq))  # centered
```


Effekte des Zentrierens:

```{r}
kidsiq %>% 
  summarise(mom_iq_avg = mean(mom_iq),
            mom_iq_c_avg = mean(mom_iq_c),
            mom_iq_sd = sd(mom_iq),
            mom_iq_c_sd = sd(mom_iq_c))
```



```{r}
kidsiq %>% 
  summarise(mom_hs_avg = mean(mom_hs),
            mom_hs_c_avg = mean(mom_hs_c),
            mom_hs_sd = sd(mom_hs),
            mom_hs_c_sd = sd(mom_hs_c))
```


```{r}
kidsiq %>% 
  count(mom_hs_c)
```


### Mit Zentrieren des binären Prädiktors

```{r}
lm2 <- lm(kid_score ~ mom_hs_c + mom_iq_c + mom_hs_c:mom_iq_c,
          data = kidsiq)
display(lm2)
```

### Ohne Zentrieren des binären Prädiktors

```{r}
lm2a <- lm(kid_score ~ mom_hs + mom_iq_c + mom_hs:mom_iq_c,
          data = kidsiq)
display(lm2a)
```

Interpretation:

- Achsenabschnitt: Ohne Highschool-Abschluss und mit mitlerer Intelligenz ist laut Modell ein Testwert (Y-Wert) von im Schnitt ca. 85 Punkten zu erwarten.

- `mom_hs`: Der Unterschied im Testwert, wenn man Mütter mit bzw. ohne HS-Abschluss und mittlerer Intelligenz vergleicht, liegt bei knapp 3 Punkte.
- `mom_iq_c`: Der Unterschied im Testwert, wenn man Mütter mit einem Punkt Unterschied im IQ-Wert vergleicht (und bei Müttern *ohne* HS-Abschluss), liegt bei 0.97 Punkten.
- `mom_hs:mom_iq_c`: Der Unterschied im Testwert im Vergleich zu `mom_iq_c`, wenn man Mütter mit einem Punkt Unterschied im IQ-Wert vergleich (und bei Müttern *mit* HS-Abschluss), liegt bei 0.97 - 0.48 = 0.49 Punkten.

### Zentriert vs. nicht-zentrierte Modelle mit einem Prädiktor

Hat man nur einen Prädiktor, so ändert das Zentrieren das Regressionsgewicht ($\beta$) nicht:

```{r}
lm2b <- lm(kid_score ~ mom_iq, data = kidsiq)
display(lm2b)
```

```{r}
lm2c <- lm(kid_score ~ mom_iq_c, data = kidsiq)
display(lm2c)
```

Im Beispiel oben hat sich durch das Zentrieren der Wert der Regressionsgewichte der Prädiktoren `mom_iq_c` und `mom_hs_c` geändert. Das liegt daran, dass mehr als ein Prädiktor (inkl. Interaktionseffekt) im Modell vorhanden ist.


## Interaktionseffekt visualisieren

```{r}
kidsiq %>% 
  ggplot(aes(x = mom_iq, y = kid_score, color = as.factor(mom_hs))) +
  geom_smooth(method = "lm") +
  geom_point() +
   scale_color_viridis_d()
```


```{r}
kidsiq %>% 
  ggplot(aes(x = mom_iq, y = kid_score, color = as.factor(mom_hs))) +
  facet_wrap(~ mom_hs) +
  geom_smooth(method = "lm") +
  geom_point()
```


## lm3: z-Transformation


```{r}
kidsiq <-
  kidsiq %>% 
  mutate(mom_iq_z = (mom_iq - mean(mom_iq)) / sd(mom_iq),
         mom_hs_z = (mom_hs - mean(mom_hs)) / sd(mom_hs))
```


```{r}
kidsiq %>% 
  count(mom_hs_z)
```


### Ohne Transformation von `mom_hs`, sondern nur `mom_iq`

```{r}
lm3 <- lm(kid_score ~ mom_hs + mom_iq_z + mom_hs:mom_iq_z, 
          data = kidsiq)

display(lm3)
```



Interpretation:

- Achsenabschnitt: *Ohne* Highschool-Abschluss und mit mitlerer Intelligenz ist laut Modell ein Testwert (Y-Wert) von im Schnitt ca. 85 Punkten zu erwarten.
- `mom_hs`: Der Unterschied im Testwert, wenn man Mütter mit bzw. ohne HS-Abschluss und mittlerer Intelligenz vergleicht, liegt bei knapp 3 Punkte.
- `mom_iq_z`: Der Unterschied im Testwert, wenn man Mütter pro zusätzlicher Stufe von `mom_iq_z` (d.h. eine SD-Einheit höher) vergleicht (und bei Müttern *ohne* HS-Abschluss), liegt bei ca. 15 Punkten.
- `mom_hs:mom_iq_c`: Der Unterschied im Testwert im Vergleich zu `mom_iq_c`, wenn man Mütter pro zusätzlicher Stufe von `mom_iq_c` (d.h. eine SD-Einheit höher) vergleicht (und bei Müttern *mit* HS-Abschluss), liegt bei ca. 15 - 7 ) 8 Punkten.



### Mit z-Transformation von `mom_hs`


```{r}
kidsiq %>% 
  summarise(mom_hs_sd = sd(mom_hs),
            mom_hs_avg = mean(mom_hs))
```



```{r}
lm3a <- lm(kid_score ~ mom_hs_z + mom_iq_z + mom_hs_z:mom_iq_z, 
          data = kidsiq)

display(lm3a)
```


Interpretation:

- Achsenabschnitt: *Ohne* Highschool-Abschluss und mit mitlerer Intelligenz ist laut Modell ein Testwert (Y-Wert) von im Schnitt ca. 87 Punkten zu erwarten.
- `mom_hs_z`: Der Unterschied im Testwert, wenn man der Bildungswert um eine SD-Einheit steigt. Dieser Wert ist hier kaum zu interpretieren. 
- `mom_iq_z`: Der Unterschied im Testwert, wenn man Mütter pro zusätzlicher Stufe von `mom_iq_z` (d.h. eine SD-Einheit höher) vergleicht (und bei Müttern mit *mittlerem* HS-Abschluss), liegt bei ca. 9 Punkten.
- `mom_hs_z:mom_iq_z`: Der Unterschied im Testwert im Vergleich zu `mom_iq_z`, wenn man Mütter pro zusätzlicher Stufe von `mom_iq_z` (d.h. eine SD-Einheit höher) vergleicht und wenn man Frauen mit einem Wert in `mom_hs_z` von 1 betrachtet. Da ein Wert von 1in `mom_hs_z` keine Entsprechung in den Daten hat, ist dieser Koeffizient kaum zu interpretieren.


### Binäre Prädiktoren nicht zentrieren/z-transformieren

Insgesamt scheint eine Standardisierung der binären Prädiktoren nur eingeschränkt nützlich zu sein. Ich empfehle, binäre Prädiktoren nicht zu zentieren oder z-transfomieren, sondern sie zu belassen, wie sie sind oder eine z2-Transformation anzuwenden.


### z2-Transformation

```{r}
kidsiq <-
  kidsiq %>% 
  mutate(mom_iq_z2 = (mom_iq - mean(mom_iq)) / (2*sd(mom_iq)),
         mom_hs_z2 = (mom_hs - mean(mom_hs)) / (2*sd(mom_hs)))
```



```{r}
kidsiq %>% 
  count(mom_hs_z)
```


```{r}
kidsiq %>% 
  count(mom_hs_z2)
```




```{r}
lm3b <- lm(kid_score ~ mom_hs_z2 + mom_iq_z2 + mom_hs_z2:mom_iq_z2, 
          data = kidsiq)

display(lm3b)
```


Interpretation:

- Achsenabschnitt: Ein Kind mit mittlerer Ausprägung in den Prädiktorwerten hat laut Modell im Schnitt einen Testwert von ca. 88 Punkten.
- `mom_hs_z2`: Vergleicht man HS-Abschluss ja vs. nein und betrachtet nur Mütter mit mittlerer Intelligenz, so beträgt der erwartete Unterschied im Testwert ca. 2 Punkte.
- `mom_iq_z2`: Vergleicht man Mütter, deren IQ-Werte sich um 2 SD-Einheiten unterscheiden und die über einen mittleren Wert in HS-Abschluss verfügen, so findet man einen Unterschied von ca. 18 Punkten in den Testwerten.
- `mom_hs_z2:mom_iq_z2`: Der Unterschied im Effekt des IQ auf den Testwert zwischen Frauen ohne bzw. mit HS-Abschluss auf die Testwerte liegt bei ca. -12 Punkte, d.h. bei Frauen mit Abschluss ist der Effekt des IQ auf die Testwerte geringer.


Der Vorteil der z2-Transformation ist, dass die Koeffizienten der binären Variablen den Unterschied zwischen 0 und 1 widerspiegeln. Bei der z-Transformation spiegeln Sie den *halben* Unterschied zwischen dem 0-Wert bzw. 1-Wert wider.

## Binäre Prädiktoren besser nicht standardisieren

Insgesamt ist die ganze Angelegenheit der Interpretation von standardisierten Prädiktoren nicht einfach. Ich empfehle daher, binäre Prädiktoren nicht zu standardisieren.






# Modelle mit `log(y)`

4.4 in ARM

$y=ab$, $y ~ x*y$ --> log(Y)


*Multiplikative Zusammenhänge!*

S. 59

log(y) = b0 + b1*x1 + ...  | eponenziere

y = e^(b0 + b1*x1 + ... )

y = e^b0 * e^b1x1 * ...


## lm4: earn_log


```{r}
earn <-
  earn %>% 
  mutate(earn_log = log(earn))
```

Zur Basis e.

*Achtung: log nur für x > 0!*


```{r}
lm4 <- lm(earn_log ~ height, 
          data = earn %>% filter(earn > 0))
display(lm4)
```

Was bedeutet der Wert 0.06?

--> Steigt X (height) um 1, so steigt im Modell Y um 0.06 log-Punkte: `earn` steigt um *6%*!



Zum Vergleich: additives Modell:

```{r}
lm4a <- lm(earn ~ height, 
          data = earn %>% filter(earn > 0))
display(lm4a)
```

Hier leider R^2 beim multiplikativen Modell (log-Modell) nicht besser, entgegen der Erwartung.


## lm5: earn_log mit zwei Prädiktoren

```{r}
earn %>% 
  count(sex)
```

Leider wissen wir nicht, ob Frauen mit 1 oder mit 2 codiert sind. Gehen wir davon aus, dass Männer mit 1 kodiert sind (vgl. Buch ARM, S. 61).

```{r}
earn <-
  earn %>% 
  mutate(male = case_when(
    sex == 2 ~ 0,  # Frau
    sex == 1 ~ 1))  # Mann
```



```{r}
lm5 <- lm(earn_log ~ height + male,
          data = earn %>% filter(earn > 0))
display(lm5)
```


## lm6: Mit z-Transformation und Interaktion

```{r}
earn <-
  earn %>% 
  mutate(height_z = scale(height))
```


```{r}
lm6 <- lm(earn_log ~ height_z + male + height_z:male,
          data = earn %>% filter(earn > 0))
display(lm6)
```


Delogarithimieren zur Interpretation der Koeffizienten

```{r}
exp(9.52)
```


```{r}
exp(0.06)
```

```{r}
exp(0.42)
```



Die Reihenfolge der Prädiktoren spielt *keine* Rolle:

```{r}
lm6a <- lm(earn_log ~ height_z:male + male + height_z ,
          data = earn %>% filter(earn > 0))
display(lm6)
```


# LogY-LogX-Modelle

```{r}
earn <-
  earn %>% 
  mutate(height_log = log(height))
```


```{r}
lm7 <- lm(earn_log ~ height_log + male,
          data = earn %>% filter(earn > 0))
display(lm7)
```



# Weitere Transformationen

## Diskretisierung metrischer Prädiktoren

```{r}
lm7 <- lm(kid_score ~ as.factor(mom_work),
          data = kidsiq)
display(lm7)
```


# "Buschbeispiel" - `mesquite`

## Daten laden: `mesquite`

```{r}
mesquite <- read_csv("https://raw.githubusercontent.com/sebastiansauer/2021-sose/master/data/ARM/mesquite.csv")
```

```{r}
glimpse(mesquite)
```

## Lineares Modell mit allen Prädiktoren

Vgl. S. 70 in ARM; die Daten passen nicht ganz zum Buch. Die Werte weichen etwas zum Buch ab.

```{r}
lm7 <- lm(LeafWt ~ ., data = mesquite)
display(lm7)
```


## Multiplikatives Modell

```{r}
lm8 <- lm(log(LeafWt) ~ log(Diam1) + log(Diam2) + log(TotHt) + log (CanHt) + log(Dens) + Group,
          data = mesquite)

display(lm8)
```


# Zusammenfassung

Zahlenbeispiel zu IQ

- MW = 100
- sd = 15
- Messwert (X) = 115

## Zentrieren (c-Transformation)

Wir verschieben wir den Nullpunkt auf den MW.


Nutzen: Achsenabschnitt (und Interaktionseffekte) werden  damit interpretierbar(er).

Interpreation von Achsenabscnitt: Y-Wert, wenn X beim MW (also mittlerer X-Wert)

Rechnen: x_c = X - mean(X)

Z.B. X=115, mw_X = 100 -> X_c = 115 - 100 = 15

Der zentrierte Wert X_c zeigt also den *Abstand zum Mittelwert.*




# Z-Transformieren

Z-transformierte Werte sind immer auch zentriert.

Nutzen: Regressiongewichte werden vergleichbar, da gleiche Skalierung.

Rechnen: x_z = z_c / sd(X)

z.B. X=115, mw_X = 100, sd_X = 15

x_z = x_z / 15 = 15 / 15 = 1


